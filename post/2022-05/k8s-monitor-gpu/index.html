<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Monitor GPU resources of Kubernetes clusters - SoByte</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6356451834813761" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E8GRRGBTEZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E8GRRGBTEZ');
</script>


<meta name="author" content="" /><meta name="description" content="Learn how to monitor the GPU resources of a Kubernetes cluster." /><meta name="keywords" content="kubernetes, Monitor Gpu" />






<meta name="generator" content="Hugo 0.102.0 with theme even" />


<link rel="canonical" href="https://www.sobyte.net/post/2022-05/k8s-monitor-gpu/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">


<meta property="og:title" content="Monitor GPU resources of Kubernetes clusters" />
<meta property="og:description" content="Learn how to monitor the GPU resources of a Kubernetes cluster." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.sobyte.net/post/2022-05/k8s-monitor-gpu/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-05-19T19:12:56+08:00" />
<meta property="article:modified_time" content="2022-05-19T19:12:56+08:00" />

<meta itemprop="name" content="Monitor GPU resources of Kubernetes clusters">
<meta itemprop="description" content="Learn how to monitor the GPU resources of a Kubernetes cluster."><meta itemprop="datePublished" content="2022-05-19T19:12:56+08:00" />
<meta itemprop="dateModified" content="2022-05-19T19:12:56+08:00" />
<meta itemprop="wordCount" content="1856">
<meta itemprop="keywords" content="kubernetes," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Monitor GPU resources of Kubernetes clusters"/>
<meta name="twitter:description" content="Learn how to monitor the GPU resources of a Kubernetes cluster."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SOBYTE</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SOBYTE</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Monitor GPU resources of Kubernetes clusters</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-05-19 19:12:56 </span>
        <div class="post-category">
            <a href="/categories/tutorials/"> tutorials </a>
            </div>
          <span class="more-meta"> 1856 words </span>
          <span class="more-meta"> 9 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-background-notes">1. Background Notes</a>
          <ul>
            <li><a href="#11-requirement-description">1.1 Requirement Description</a></li>
            <li><a href="#12-nvidia-dcgm">1.2 NVIDIA DCGM</a></li>
            <li><a href="#13-nvidia-exporter">1.3 NVIDIA exporter</a></li>
            <li><a href="#14-kubelet-device-monitoring">1.4 Kubelet Device Monitoring</a></li>
          </ul>
        </li>
        <li><a href="#2-gpu-monitoring">2. GPU monitoring</a>
          <ul>
            <li><a href="#21-deployment-instructions">2.1 Deployment Instructions</a></li>
            <li><a href="#22-deploy-dcgm-exporter">2.2 Deploy dcgm-exporter</a></li>
            <li><a href="#view-dcgm-metrics">View DCGM metrics</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h2 id="1-background-notes">1. Background Notes</h2>
<h3 id="11-requirement-description">1.1 Requirement Description</h3>
<p>For SRE team, it is critical to implement monitoring of large-scale GPU resources on AI and high performance computing platforms.SRE team can understand workload and other related performance through GPU metrics to optimize resource allocation, improve resource utilization and abnormality diagnosis to improve the overall performance of data center resources. In addition to SRE and infrastructure teams, whether you are a researcher working on GPU acceleration direction or a data center architect, you can understand GPU utilization and work saturation for capacity planning and task scheduling, etc. through relevant monitoring metrics.</p>
<p>With the containerization of AI/ML workloads and the adoption of Kubernetes solutions with dynamic scaling features for scheduling platforms, the urgency of monitoring for them is increasing. In this article, we will introduce NVIDIA Data Center GPU Manager (DCGM) and how it can be integrated into open source tools such as Prometheus and Grafana to enable a holistic solution for GPU monitoring in Kubernetes.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/38ccd7fd48ca4a8e8f59c5680cdb2b11.png" alt="k8s gpu"></p>
<h3 id="12-nvidia-dcgm">1.2 NVIDIA DCGM</h3>
<p>NVIDIA DCGM is an all-in-one tool for managing and monitoring large-scale clusters of NVIDIA GPUs on Linux-based systems. It is a low-overhead tool that provides a variety of capabilities including active health monitoring, diagnostics, system validation, policy, power and clock management, configuration management, and auditing.</p>
<p>DCGM provides APIs for collecting GPU telemetry. of particular interest are GPU utilization metrics, memory metrics, and traffic metrics. DCGM provides clients for various languages such as C and Python. for integration with the container ecosystem, a Go-bound implementation based on DCGM APIs is provided.</p>
<h3 id="13-nvidia-exporter">1.3 NVIDIA exporter</h3>
<p>Monitoring systems typically consist of a metrics collector, a time series database for storing metrics, and visual components. An example is the CNCF graduation project Prometheus, which together with Grafana forms a monitoring integration solution. Prometheus, kube-state-metrics, and node_exporter are deployed together to capture cluster metrics and node metrics such as CPU utilization for Kubernetes API objects. The following figure shows an example architecture of Prometheus.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/5955aa8be8994e949bac409e02c54ecf.png" alt="NVIDIA"></p>
<p>Building on the Go API described earlier, GPU metrics can be exposed to Prometheus via DCGM. NVIDIA has built the dcgm-exporter project for this purpose.</p>
<p>The dcgm-exporter uses Go bindings to collect GPU telemetry data from DCGM and then expose the metrics to Prometheus via the http interface (/metrics).</p>
<p>The dcgm-exporter can customize the GPU metrics collected by DCGM by using a configuration file in csv format.</p>
<h3 id="14-kubelet-device-monitoring">1.4 Kubelet Device Monitoring</h3>
<p>The dcgm-exporter collects metrics for all available GPUs on a node. However, in Kubernetes, when a node requests GPU resources, it may not be possible to determine which GPUs will be assigned to pods. starting with v1.13, Kubelet adds a device monitoring feature that allows the pod-resources socket to know the devices assigned to pods, which includes the pod name, pod namespace, and device ID.</p>
<p>The http service in dcgm-exporter connects to the pod-resources service in kubelet (/var/lib/kubelet/pod-resources) to identify the GPU device running on the pod and adds the pod-related information of the GPU device to the collected metrics.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/8d913fdeeb8349e6805e4f6794138ce6.png" alt="Kubelet Device Monitoring"></p>
<h2 id="2-gpu-monitoring">2. GPU monitoring</h2>
<h3 id="21-deployment-instructions">2.1 Deployment Instructions</h3>
<p>Here are some examples of setting up the dcgm-exporter. If using NVIDIA GPU Operator, then dcgm-exporter is also one of the deployment components.</p>
<p>The documentation contains steps for setting up a Kubernetes cluster. For brevity, it is assumed that a Kubernetes cluster already exists with NVIDIA software components running, such as drivers, container runtimes, and Kubernetes device plug-ins. Grafana can also be easily deployed when deploying Prometheus using Prometheus Operator, and in that article, a single-node Kubernetes cluster was used for simplicity.</p>
<p>When setting up the community-provided Helm chart for Prometheus Operator, Grafana must be exposed for external access, and prometheusSpec.serviceMonitorSelectorNilUsesHelmValues must be set to false.</p>
<p>In short, setting up monitoring consists of running the following command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"> helm repo add prometheus-community <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>https://prometheus-community.github.io/helm-charts
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ helm repo update
</span></span><span class="line"><span class="cl">$ helm inspect values prometheus-community/kube-prometheus-stack &gt; /tmp/kube-prometheus-stack.values
</span></span><span class="line"><span class="cl"><span class="c1"># Edit /tmp/kube-prometheus-stack.values in your favorite editor</span>
</span></span><span class="line"><span class="cl"><span class="c1"># according to the documentation</span>
</span></span><span class="line"><span class="cl"><span class="c1"># This exposes the service via NodePort so that Prometheus/Grafana</span>
</span></span><span class="line"><span class="cl"><span class="c1"># are accessible outside the cluster with a browser</span>
</span></span><span class="line"><span class="cl">$ helm install prometheus-community/kube-prometheus-stack <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--create-namespace --namespace prometheus <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--generate-name <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--set prometheus.service.type<span class="o">=</span>NodePort <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues<span class="o">=</span><span class="nb">false</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>At this point, the cluster is configured as shown below, where all Prometheus pods and services are healthy and running.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ kubectl get pods -A
</span></span><span class="line"><span class="cl">NAMESPACE     NAME                                                              READY   STATUS    RESTARTS   AGE
</span></span><span class="line"><span class="cl">kube-system   calico-kube-controllers-8f59968d4-zrsdt                           1/1     Running   <span class="m">0</span>          18m
</span></span><span class="line"><span class="cl">kube-system   calico-node-c257f                                                 1/1     Running   <span class="m">0</span>          18m
</span></span><span class="line"><span class="cl">kube-system   coredns-f9fd979d6-c52hz                                           1/1     Running   <span class="m">0</span>          19m
</span></span><span class="line"><span class="cl">kube-system   coredns-f9fd979d6-ncbdp                                           1/1     Running   <span class="m">0</span>          19m
</span></span><span class="line"><span class="cl">kube-system   etcd-ip-172-31-27-93                                              1/1     Running   <span class="m">1</span>          19m
</span></span><span class="line"><span class="cl">kube-system   kube-apiserver-ip-172-31-27-93                                    1/1     Running   <span class="m">1</span>          19m
</span></span><span class="line"><span class="cl">kube-system   kube-controller-manager-ip-172-31-27-93                           1/1     Running   <span class="m">1</span>          19m
</span></span><span class="line"><span class="cl">kube-system   kube-proxy-b9szp                                                  1/1     Running   <span class="m">1</span>          19m
</span></span><span class="line"><span class="cl">kube-system   kube-scheduler-ip-172-31-27-93                                    1/1     Running   <span class="m">1</span>          19m
</span></span><span class="line"><span class="cl">kube-system   nvidia-device-plugin-1602308324-jg842                             1/1     Running   <span class="m">0</span>          17m
</span></span><span class="line"><span class="cl">prometheus    alertmanager-kube-prometheus-stack-1602-alertmanager-0            2/2     Running   <span class="m">0</span>          92s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-operator-c4bc5c4d5-f5vzc               2/2     Running   <span class="m">0</span>          98s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-grafana-6b4fc97f8f-66kdv         2/2     Running   <span class="m">0</span>          98s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-kube-state-metrics-76887bqzv2b   1/1     Running   <span class="m">0</span>          98s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-prometheus-node-exporter-rrk9l   1/1     Running   <span class="m">0</span>          98s
</span></span><span class="line"><span class="cl">prometheus    prometheus-kube-prometheus-stack-1602-prometheus-0                3/3     Running   <span class="m">1</span>          92s
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">$ kubectl get svc -A
</span></span><span class="line"><span class="cl">NAMESPACE     NAME                                                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>                        AGE
</span></span><span class="line"><span class="cl">default       kubernetes                                                  ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP                        20m
</span></span><span class="line"><span class="cl">kube-system   kube-dns                                                    ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP         20m
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-coredns                          ClusterIP   None             &lt;none&gt;        9153/TCP                       2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-controller-manager          ClusterIP   None             &lt;none&gt;        10252/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-etcd                        ClusterIP   None             &lt;none&gt;        2379/TCP                       2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-proxy                       ClusterIP   None             &lt;none&gt;        10249/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-scheduler                   ClusterIP   None             &lt;none&gt;        10251/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kubelet                          ClusterIP   None             &lt;none&gt;        10250/TCP,10255/TCP,4194/TCP   2m12s
</span></span><span class="line"><span class="cl">prometheus    alertmanager-operated                                       ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP     2m12s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-alertmanager                     ClusterIP   10.104.106.174   &lt;none&gt;        9093/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-operator                         ClusterIP   10.98.165.148    &lt;none&gt;        8080/TCP,443/TCP               2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-prometheus                       NodePort    10.105.3.19      &lt;none&gt;        9090:30090/TCP                 2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-grafana                    ClusterIP   10.100.178.41    &lt;none&gt;        80/TCP                         2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-kube-state-metrics         ClusterIP   10.100.119.13    &lt;none&gt;        8080/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-prometheus-node-exporter   ClusterIP   10.100.56.74     &lt;none&gt;        9100/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    prometheus-operated                                         ClusterIP   None             &lt;none&gt;        9090/TCP                       2m12s
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="22-deploy-dcgm-exporter">2.2 Deploy dcgm-exporter</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ helm repo add gpu-helm-charts <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>https://nvidia.github.io/gpu-monitoring-tools/helm-charts
</span></span><span class="line"><span class="cl">$ helm repo update
</span></span></code></pre></td></tr></table>
</div>
</div><p>Installation with helm.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ helm install <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   --generate-name <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   gpu-helm-charts/dcgm-exporter
</span></span></code></pre></td></tr></table>
</div>
</div><p>Result Verification.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ helm ls
</span></span><span class="line"><span class="cl">NAME                            NAMESPACE       REVISION        APP VERSION
</span></span><span class="line"><span class="cl">dcgm-exporter-1-1601677302      default         <span class="m">1</span>               dcgm-exporter-1.1.0             2.0.10
</span></span><span class="line"><span class="cl">nvidia-device-plugin-1601662841 default         <span class="m">1</span>          nvidia-device-plugin-0.7.0      0.7.0
</span></span></code></pre></td></tr></table>
</div>
</div><p>Prometheus and Grafana services are exposed as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">$ kubectl get svc -A
</span></span><span class="line"><span class="cl">NAMESPACE     NAME                                                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>                        AGE
</span></span><span class="line"><span class="cl">default       dcgm-exporter                                             ClusterIP   10.99.34.128     &lt;none&gt;        9400/TCP                       43d
</span></span><span class="line"><span class="cl">default       kubernetes                                                  ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP                        20m
</span></span><span class="line"><span class="cl">kube-system   kube-dns                                                    ClusterIP   10.96.0.10       &lt;none&gt;        53/UDP,53/TCP,9153/TCP         20m
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-coredns                          ClusterIP   None             &lt;none&gt;        9153/TCP                       2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-controller-manager          ClusterIP   None             &lt;none&gt;        10252/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-etcd                        ClusterIP   None             &lt;none&gt;        2379/TCP                       2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-proxy                       ClusterIP   None             &lt;none&gt;        10249/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kube-scheduler                   ClusterIP   None             &lt;none&gt;        10251/TCP                      2m18s
</span></span><span class="line"><span class="cl">kube-system   kube-prometheus-stack-1602-kubelet                          ClusterIP   None             &lt;none&gt;        10250/TCP,10255/TCP,4194/TCP   2m12s
</span></span><span class="line"><span class="cl">prometheus    alertmanager-operated                                       ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP     2m12s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-alertmanager                     ClusterIP   10.104.106.174   &lt;none&gt;        9093/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-operator                         ClusterIP   10.98.165.148    &lt;none&gt;        8080/TCP,443/TCP               2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602-prometheus                       NodePort    10.105.3.19      &lt;none&gt;        9090:30090/TCP                 2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-grafana                    ClusterIP   10.100.178.41    &lt;none&gt;        80:32032/TCP                   2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-kube-state-metrics         ClusterIP   10.100.119.13    &lt;none&gt;        8080/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    kube-prometheus-stack-1602309230-prometheus-node-exporter   ClusterIP   10.100.56.74     &lt;none&gt;        9100/TCP                       2m18s
</span></span><span class="line"><span class="cl">prometheus    prometheus-operated                                         ClusterIP   None             &lt;none&gt;        9090/TCP                       2m12s
</span></span></code></pre></td></tr></table>
</div>
</div><p>Access the Grafana home page using the Grafana service exposed on port 32032. Login to the dashboard using the credentials set in the Prometheus chart: adminPassword field in prometheus.values.</p>
<p>Now to start a Grafana dashboard for GPU metrics, import the NVIDIA dashboard from the Grafana dashboard (<a href="https://grafana.com/grafana/dashboards/12239">https://grafana.com/grafana/dashboards/12239</a>).</p>
<h3 id="view-dcgm-metrics">View DCGM metrics</h3>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/03437dc72536457b80c5ff58b69822df.png" alt="Grafana dashboard"></p>
<p>Now run some GPU workloads, for this purpose, the DCGM community provides a CUDA load generator called dcgmproftester, which can be used to generate deterministic CUDA workloads for reading and verifying GPU metrics.</p>
<p>To generate a Pod, you must first download DCGM and make an image of it. The following script creates a container that can be used to run dcgmproftester. This container can be found in the NVIDIA DockerHub repository.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#!/usr/bin/env bash</span>
</span></span><span class="line"><span class="cl"><span class="nb">set</span> -exo pipefail
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">mkdir -p /tmp/dcgm-docker
</span></span><span class="line"><span class="cl"><span class="nb">pushd</span> /tmp/dcgm-docker
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">cat &gt; Dockerfile <span class="s">&lt;&lt;EOF
</span></span></span><span class="line"><span class="cl"><span class="s">ARG BASE_DIST
</span></span></span><span class="line"><span class="cl"><span class="s">ARG CUDA_VER
</span></span></span><span class="line"><span class="cl"><span class="s">FROM nvidia/cuda:\${CUDA_VER}-base-\${BASE_DIST}
</span></span></span><span class="line"><span class="cl"><span class="s">LABEL io.k8s.display-name=&#34;NVIDIA dcgmproftester&#34;
</span></span></span><span class="line"><span class="cl"><span class="s"> 
</span></span></span><span class="line"><span class="cl"><span class="s">ARG DCGM_VERSION
</span></span></span><span class="line"><span class="cl"><span class="s"> 
</span></span></span><span class="line"><span class="cl"><span class="s">WORKDIR /dcgm
</span></span></span><span class="line"><span class="cl"><span class="s">RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
</span></span></span><span class="line"><span class="cl"><span class="s">    libgomp1 \
</span></span></span><span class="line"><span class="cl"><span class="s">    wget &amp;&amp; \
</span></span></span><span class="line"><span class="cl"><span class="s">    rm -rf /var/lib/apt/lists/* &amp;&amp; \
</span></span></span><span class="line"><span class="cl"><span class="s">    wget --no-check-certificate https://developer.download.nvidia.com/compute/redist/dcgm/\${DCGM_VERSION}/DEBS/datacenter-gpu-manager_\${DCGM_VERSION}_amd64.deb &amp;&amp; \
</span></span></span><span class="line"><span class="cl"><span class="s">    dpkg -i datacenter-gpu-manager_*.deb &amp;&amp; \
</span></span></span><span class="line"><span class="cl"><span class="s">    rm -f datacenter-gpu-manager_*.deb
</span></span></span><span class="line"><span class="cl"><span class="s"> 
</span></span></span><span class="line"><span class="cl"><span class="s">ENTRYPOINT [&#34;/usr/bin/dcgmproftester11&#34;]
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="nv">DIR</span><span class="o">=</span>.
</span></span><span class="line"><span class="cl"><span class="nv">DCGM_REL_VERSION</span><span class="o">=</span>2.0.10
</span></span><span class="line"><span class="cl"><span class="nv">BASE_DIST</span><span class="o">=</span>ubuntu18.04
</span></span><span class="line"><span class="cl"><span class="nv">CUDA_VER</span><span class="o">=</span>11.0
</span></span><span class="line"><span class="cl"><span class="nv">IMAGE_NAME</span><span class="o">=</span>nvidia/samples:dcgmproftester-<span class="nv">$DCGM_REL_VERSION</span>-cuda<span class="nv">$CUDA_VER</span>-<span class="nv">$BASE_DIST</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">docker build --pull <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        -t <span class="s2">&#34;</span><span class="nv">$IMAGE_NAME</span><span class="s2">&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --build-arg <span class="nv">DCGM_VERSION</span><span class="o">=</span><span class="nv">$DCGM_REL_VERSION</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --build-arg <span class="nv">BASE_DIST</span><span class="o">=</span><span class="nv">$BASE_DIST</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --build-arg <span class="nv">CUDA_VER</span><span class="o">=</span><span class="nv">$CUDA_VER</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        --file Dockerfile <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>        <span class="s2">&#34;</span><span class="nv">$DIR</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="nb">popd</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Before deploying a container on a Kubernetes cluster, try running it directly using Docker. In this example, use Tensor Cores to trigger FP16 matrix multiplication by specifying -t 1004 and run the test at -d 45 (45 seconds). You can try to run other workloads by modifying the -t parameter.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">Skipping CreateDcgmGroups<span class="o">()</span> since DCGM validation is disabled
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR: <span class="m">1024</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT: <span class="m">40</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: <span class="m">65536</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR: <span class="m">7</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR: <span class="m">5</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH: <span class="m">256</span>
</span></span><span class="line"><span class="cl">CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE: <span class="m">5001000</span>
</span></span><span class="line"><span class="cl">Max Memory bandwidth: <span class="m">320064000000</span> bytes <span class="o">(</span>320.06 GiB<span class="o">)</span>
</span></span><span class="line"><span class="cl">CudaInit completed successfully.
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl">Skipping WatchFields<span class="o">()</span> since DCGM validation is disabled
</span></span><span class="line"><span class="cl">TensorEngineActive: generated ???, dcgm 0.000 <span class="o">(</span>27605.2 gflops<span class="o">)</span>
</span></span><span class="line"><span class="cl">TensorEngineActive: generated ???, dcgm 0.000 <span class="o">(</span>28697.6 gflops<span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Deploy it to a Kubernetes cluster and you can observe the corresponding metrics through the Grafana dashboard. The sample code is shown below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"> cat <span class="s">&lt;&lt; EOF | kubectl create -f -
</span></span></span><span class="line"><span class="cl"><span class="s"> apiVersion: v1
</span></span></span><span class="line"><span class="cl"><span class="s"> kind: Pod
</span></span></span><span class="line"><span class="cl"><span class="s"> metadata:
</span></span></span><span class="line"><span class="cl"><span class="s">   name: dcgmproftester
</span></span></span><span class="line"><span class="cl"><span class="s"> spec:
</span></span></span><span class="line"><span class="cl"><span class="s">   restartPolicy: OnFailure
</span></span></span><span class="line"><span class="cl"><span class="s">   containers:
</span></span></span><span class="line"><span class="cl"><span class="s">   - name: dcgmproftester11
</span></span></span><span class="line"><span class="cl"><span class="s">     image: nvidia/samples:dcgmproftester-2.0.10-cuda11.0-ubuntu18.04
</span></span></span><span class="line"><span class="cl"><span class="s">     args: [&#34;--no-dcgm-validation&#34;, &#34;-t 1004&#34;, &#34;-d 120&#34;]
</span></span></span><span class="line"><span class="cl"><span class="s">     resources:
</span></span></span><span class="line"><span class="cl"><span class="s">       limits:
</span></span></span><span class="line"><span class="cl"><span class="s">          nvidia.com/gpu: 1
</span></span></span><span class="line"><span class="cl"><span class="s">     securityContext:
</span></span></span><span class="line"><span class="cl"><span class="s">       capabilities:
</span></span></span><span class="line"><span class="cl"><span class="s">          add: [&#34;SYS_ADMIN&#34;]
</span></span></span><span class="line"><span class="cl"><span class="s"> 
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The dcgmproftester pod can be seen running healthily and the metrics are subsequently displayed on the Grafana dashboard. GPU utilization (GrActive) has reached a peak utilization of 98% and other interesting metrics may be found, such as power or GPU memory.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ kubectl get pods -A
</span></span><span class="line"><span class="cl">NAMESPACE     NAME                                                              
</span></span><span class="line"><span class="cl">READY   STATUS    RESTARTS   AGE
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">default       dcgmproftester                                                    
</span></span><span class="line"><span class="cl">1/1     Running   <span class="m">0</span>          6s
</span></span></code></pre></td></tr></table>
</div>
</div><p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/ae380ff2c9714beb89409f8a0e0dae91.png" alt="Grafana dashboard"></p>
<p>DCGM has recently added a number of device-level metrics. These include fine-grained GPU utilization metrics that monitor SM occupancy and Tensor Core utilization. For more information, see Profiling Metrics in the DCGM User Guide.</p>
<p>The following figure shows the monitoring metrics provided by dcgm-exporter as fetched by Prometheus.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/b6661e7243274b718efc7e0ebef9210e.png" alt="Prometheus"></p>
<p>You can customize the Grafana dashboard to include additional metrics from DCGM. In this case, add Tensor Core utilization to the dashboard by editing the Grafana JSON file provided on the repo, or you can use Grafana&rsquo;s web interface for editing.</p>
<p>The dashboard below includes Tensor Core utilization. After restarting the dcgmproftester container, you can see that Tensor Core on T4 has reached about 87% utilization.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images1/2022/05/19/b936933e558c43069c9206bfe3b167b8.png" alt="dashboard"></p>
<p>By using GPU metrics as custom metrics and Prometheus Adapter, you can use Horizontal Pod Autoscaler to scale the number of Pods based on GPU utilization or other metrics.</p>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kubernetes/">kubernetes</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2022-05/vmalert/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Use vmalert instead of Prometheus to monitor alarms</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2022-05/go-linux-container/">
            <span class="next-text nav-default">Dissecting Linux container implementation principles using Go</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.sobyte.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>



<script type="text/javascript" src="/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js"></script>








</body>
</html>
